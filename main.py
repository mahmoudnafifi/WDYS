"""This script is to evaluate the WDYS method on a given dataset."""
import argparse
import os
import io
from PIL import Image
import numpy as np
import pickle
from prettytable import PrettyTable
import wdys_zs_classification as wdys

def get_args():
  parser = argparse.ArgumentParser(
    description='Evaluate WDYS zero-shot image classifier.')

  parser.add_argument(
    '--dataset_name', type=str,
    help='Dataset name.',
    choices=['caltech', 'cars', 'cifar10', 'cifar100',
             'dtd', 'food', 'imagenet', 'pets', 'places',
             'sun397'])

  parser.add_argument(
    '--data_folder', type=str,
    help='Folder of datasets.', default='../data/')

  parser.add_argument(
    '--recompute_features',
    action='store_true', help='To recompute CLIP features.')

  parser.add_argument(
    '--model_name', type=str, default='clip-l/14',
    help='Cross-modal embedding encoder model name.',
    choices=['clip-l/14', 'clip-b/16', 'clip-b/32']
  )

  parser.add_argument(
    '--use_image_features',
    action='store_true', help='To use image features.')

  parser.add_argument(
    '--use_description_features',
    action='store_true',
    help='To use features of image description generated by Gemini Pro.')

  parser.add_argument(
    '--use_predicted_class_features', action='store_true',
    help='To use features of initial class predicted by Gemini Pro.')

  parser.add_argument(
    '--use_class_descriptions', action='store_true',
    help='To use features of class descriptions produced by Gemini Pro.')

  parser.add_argument('--use_class_name', action='store_true',
                      help='To use features of class names.')

  parser.add_argument('--use_a_photo_of', action='store_true',
                      help='To use features of "A photo of {class name}.')

  parser.add_argument('--gemini_eval', action='store_true',
                      help='To report Gemini evaluation results.')

  parser.add_argument(
    '--verbose', action='store_true',
    help='To print detailed progress information during classification.')

  return parser.parse_args()


if __name__ == '__main__':
  args = get_args()
  if sum([args.use_image_features, args.use_description_features,
          args.use_predicted_class_features]) < 1:
    raise AssertionError(
      "At least one of the options '--use_image_features', "
      "'--use_description_features', '--use_predicted_class_features' "
      "must be used.")

  if sum([args.use_class_descriptions, args.use_class_name, args.use_a_photo_of]
         ) != 1:
    raise AssertionError(
      "One of the options '--use_class_descriptions', '--use_class_name', "
      "'--use_a_photo_of' must be used.")

  class_embedding_method = ''
  if args.use_class_name:
    class_embedding_method += ' class_name'
  if args.use_a_photo_of:
    class_embedding_method += ' a_photo_of_class_name'
  if args.use_class_descriptions:
    class_embedding_method += ' class_description'
  if class_embedding_method == '':
    class_embedding_method = None
  data_folder = args.data_folder
  dataset_name = args.dataset_name
  recompute_features = args.recompute_features
  model_name = args.model_name
  use_image_features = args.use_image_features
  use_description_features = args.use_description_features
  use_predicted_class_features = args.use_predicted_class_features
  report_gemini_eval = args.gemini_eval
  verbose = args.verbose
  experiment_info = {
    'data_folder': data_folder,
    'dataset': dataset_name,
    'class_embedding_method': class_embedding_method,
    'model_name': model_name,
    'recompute_features': recompute_features,
    'use_image': use_image_features,
    'use_image_description': use_description_features,
    'use_gemini_prediction': use_predicted_class_features,
    'report_gemini_evaluation': report_gemini_eval,
    'verbose': verbose,
  }

  table = PrettyTable()
  table.field_names = ['Key', 'Value']
  for key, value in experiment_info.items():
    table.add_row([key, value])
  print(table)

  if not os.path.exists(os.path.join(data_folder, dataset_name, 'classes.pkl')):
    raise FileNotFoundError(
      'The dataset class labels file could not be found: '
      f"{os.path.join(data_folder, dataset_name, 'classes.pkl')}")

  if not os.path.exists(os.path.join(data_folder, dataset_name, 'images')):
    raise FileNotFoundError('The image folder could not be found: '
                            f"{os.path.join(data_folder, dataset_name)}")

  print(f'Loading class labels data ...')
  with open(os.path.join(data_folder, dataset_name, 'classes.pkl'), 'rb') as f:
    dataset_classes = pickle.load(f)
  print(f'Done!')

  print('Building WDYS zero-shot classification model.')
  model = wdys.WDYS(dataset_classes, experiment_info)
  print(f'Done!')

  testing_files = [file for file in os.listdir(
    os.path.join(data_folder, dataset_name, 'images')) if file.endswith('.pkl')]

  print('Processing...')
  if report_gemini_eval:
    gemini_accuracy = 0
  else:
    gemini_accuracy = None
  accuracy = top_5_accuracy = count = 0
  if verbose:
    total_files = 0
    for testing_file in testing_files:
      with open(os.path.join(data_folder, dataset_name, 'images', testing_file),
                'rb') as f:
        image_data = pickle.load(f)
        total_files += len(image_data['image_bytes'])
  else:
    total_files = None

  predicted_classes = []
  true_classes = []

  for file_i, testing_file in enumerate(testing_files):
    with open(os.path.join(data_folder, dataset_name, 'images', testing_file),
              'rb') as f:
      image_data = pickle.load(f)
      length = len(image_data['image_bytes'])
      for i in range(length):
        gt = image_data['gt_classes'][i].replace('\n', '')
        if use_image_features and recompute_features:
          image = np.array(Image.open(io.BytesIO(image_data['image_bytes'][i])))
          image_feature = None
        elif use_image_features:
          image = None
          image_feature = image_data['image_features'][i]
        else:
          image = image_feature = None

        if use_description_features and recompute_features:
          image_description = image_data['image_descriptions'][i]
          description_feature = None
        elif use_description_features:
          image_description = None
          description_feature = image_data['image_description_features'][i]
        else:
          image_description = description_feature = None

        if use_predicted_class_features and recompute_features:
          init_prediction = image_data['gemini_predictions'][i]
          init_prediction_feature = None
        elif use_predicted_class_features:
          init_prediction = None
          init_prediction_feature = image_data['gemini_prediction_features'][i]
        else:
          init_prediction = init_prediction_feature = None

        predicted_class, top_5_classes = model.classify(
          image=image, image_feature=image_feature,
          image_description=image_description,
          description_feature=description_feature,
          gemini_prediction=init_prediction,
          gemini_prediction_feature=init_prediction_feature)

        true_classes.append(gt)
        predicted_classes.append(predicted_class)

        count += 1
        if predicted_class == gt:
          accuracy += 1

        if gt in top_5_classes:
          top_5_accuracy += 1
        if report_gemini_eval:
          gemini_accuracy += image_data['gemini_eval'][i]

        if verbose:
          print(f'({count} / {total_files}): '
                f'Predicted class = {predicted_class}, '
                f'ground-truth class = {gt}')

  accuracy /= count
  top_5_accuracy /= count
  print(f'Total number of images = {count}')
  print(f'Top-1 accuracy = {round(accuracy * 100, 1)}, '
        f'Top-5 accuracy = {round(top_5_accuracy * 100, 1)}')
  if report_gemini_eval:
    gemini_accuracy /= count
    print(f'Top-1 accuracy (Gemini eval) = {round(gemini_accuracy * 100, 1)}')
